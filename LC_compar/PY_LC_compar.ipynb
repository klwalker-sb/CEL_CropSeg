{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389799fd-ce0e-4966-8fcf-429f9f928615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import geemap\n",
    "import ee\n",
    "\n",
    "ee.Initialize()\n",
    "ee.Authenticate()\n",
    "\n",
    "from LC_funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de75f70-b58e-4183-a9a2-6ccf2242b555",
   "metadata": {},
   "source": [
    "1) download Mapbiomas-Paraguay from gee or copy ready files for CEL-Pry classifications \n",
    "2) create mosaic of tiles\n",
    "3) relcassify mosaic\n",
    "4) extract raster vals at 1km x 1km sample points \n",
    "5) save agreement matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500c503-6e40-4f5d-9526-cc975b0d3dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MapBiomas Paraguay\n",
    "\n",
    "reclass_csv = \"/home/downspout-cel/paraguay_lc/lc_prods/recode/MB_PRY_recode.csv\"\n",
    "\n",
    "years=list(range(2018, 2023, 1))\n",
    "prod_dir=\"/home/downspout-cel/paraguay_lc/lc_prods/MB_PRY\"\n",
    "grid_file=\"/home/downspout-cel/paraguay_lc/Segmentations/PY_grid_8858.gpkg\"\n",
    "\n",
    "######################################################################################\n",
    "# ## 1) download MB -- error when downoading as one image so download each image tile \n",
    "MB_PRY_GEE(years, out_dir, grid_file)\n",
    "\n",
    "# ## 2) mosaic MB \n",
    "mosaics=[]\n",
    "for year in years:\n",
    "    out_mos=os.path.join(prod_dir, \"_\".join([os.path.basename(prod_dir), str(year)+\".tif\"]))\n",
    "    if not os.path.exists(out_mos):\n",
    "        file_path_list = [os.path.join(prod_dir, \"_\".join([os.path.basename(prod_dir), str(year)]), fi) for fi in os.listdir(os.path.join(prod_dir, \"_\".join([os.path.basename(prod_dir), str(year)]))) if fi.endswith(\".tif\")] \n",
    "        mosaics.append(mosaic_rasters(file_path_list, out_mos))\n",
    "    print(out_mos)\n",
    "print(mosaics)\n",
    "\n",
    "## 3) reclass MB\n",
    "for mosaic in mosaics:\n",
    "    print(mosaic)\n",
    "    reclassify_raster(raster_path=mosaic, old_new=reclass_csv, out_dir=prod_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d1f79ebf-505a-4922-b4df-8ee4ac72b9fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CEL\n",
    "\n",
    "prod_dir=\"/home/downspout-cel/paraguay_lc/lc_prods/CEL\"\n",
    "\n",
    "classifications=\"/home/downspout-cel/paraguay_lc/stac/grids/\"\n",
    "filter_string=\"base1000\"\n",
    "year=str(2022)\n",
    "\n",
    "######################################################################################\n",
    "## 1) find grids cells that are ready, copy to lc_prod/CEL directory\n",
    "for full_dir in [os.path.join(classifications, i, \"comp\") for i in sorted([ i for i in os.listdir(classifications) if len(i)==6])]:\n",
    "    if os.path.exists(full_dir):\n",
    "        class_files=[i for i in os.listdir(full_dir) if filter_string in i]\n",
    "        if len(class_files) > 0:\n",
    "            file_to_copy = os.path.join(full_dir, class_files[0])\n",
    "            if not os.path.exists(os.path.join(prod_dir, file_to_copy)):\n",
    "                !cp $file_to_copy $prod_dir\n",
    "## 2) mosaic\n",
    "rast_mosaic = os.path.join(prod_dir, \"_\".join([os.path.basename(prod_dir), str(year)+\".tif\"]))\n",
    "mosaic_rasters(sorted([i for i in os.listdir(prod_dir) if (filter_string in i and i.endswith(\".tif\"))]), out_mos=rast_mosaic)\n",
    "## 3) reclass\n",
    "reclassify_raster(raster_path=rast_mosaic, \n",
    "                  old_new=\"/downspout-cel/paraguay_lc/lc_prods/recode/\"+os.path.basename(prod_dir)+\"_recode.csv\", \n",
    "                  out_dir=prod_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e4209-340b-4831-9c12-5bd3a5dce8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BAUMANN \n",
    "\n",
    "prod_dir = \"/home/downspout-cel/paraguay_lc/lc_prods/Baumann\"\n",
    "\n",
    "######################################################################################\n",
    "## 3) reclass \n",
    "for rast in [os.path.join(prod_dir, i) for i in os.listdir(prod_dir) if (\"ForestLoss\" not in i and \"reclass\" not in i)]:\n",
    "    print(rast)\n",
    "    reclassify_raster(raster_path=rast, \n",
    "                      old_new=\"/home/downspout-cel/paraguay_lc/lc_prods/recode/\"+os.path.basename(prod_dir)+\"_recode.csv\", \n",
    "                      out_dir=prod_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bfabdbd6-2857-420f-9ace-b83d68daccd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204b341-6c95-4f0d-8627-2cd35e7de97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 4) extract raster vals at sample points \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "samp_pts=\"/home/downspout-cel/paraguay_lc/lc_prods/fishnet_1km.csv\"\n",
    "df = pd.read_csv(samp_pts)\n",
    "coords_list = [np.float64(i[7:-1].split(\" \")) for i in df['geometry']]\n",
    "\n",
    "for rast in glob(\"/home/downspout-cel/paraguay_lc/lc_prods/**/*_reclass.tif\", recursive=True):\n",
    "    with rio.open(rast) as src:\n",
    "        ## create column for raster, row is raster value at each coordinate\n",
    "        field_pts[os.path.basename(rast).replace(\"_reclass.tif\", \"\")] = [x[0] for x in src.sample([transform_point_coords(inepsg=CRS.from_user_input(8858), outepsg=src.crs, XYcoords=i) for i in coords_list])]\n",
    "    print(rast)\n",
    "## remove rows where they're ALL zero\n",
    "df = field_pts.loc[field_pts['CEL'] * field_pts['Baumann'] * field_pts['MB_PRY'] != 0]\n",
    "df.to_csv(samp_pts.replace(\".csv\", \"_vals.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1dc85f-7136-45fb-aec1-ba465e872bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) save agreement matrix \n",
    "\n",
    "for LC_prods in [[\"CEL\", \"Baumann\"], [\"MB_PRY\", \"Baumann\"], [\"CEL\", \"MB_PRY\"]]:\n",
    "\n",
    "    ## subset cols \n",
    "    matrix_df = df[[LC_prods[0], LC_prods[1]]]\n",
    "    ## delete if ANY are zero\n",
    "    matrix_df = matrix_df[(matrix_df != 0).all(1)]\n",
    "\n",
    "    ## first is true value, second\n",
    "    true = matrix_df[LC_prods[0]]\n",
    "    pred =  matrix_df[LC_prods[1]]\n",
    "    agree_arr = confusion_matrix(true, pred)\n",
    "    df_ag = pd.DataFrame(agree_arr)\n",
    "    df_ag.to_csv(\"/home/downspout-cel/paraguay_lc/lc_prods/\"+\"_\".join([os.path.basename(samp_pts)[:-4],\"agree\",LC_prods[0],LC_prods[1]+\".csv\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.helpers38] *",
   "language": "python",
   "name": "conda-env-.helpers38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
